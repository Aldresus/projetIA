{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Intelligence Artificielle\n",
    "\n",
    "Groupe 4 :\n",
    "- CHAMPY Hugo\n",
    "- SEITZ Tom\n",
    "- WALTER Loïc\n",
    "- ZITTEL Laureline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable Ethique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "L’entreprise HumanForYou, basée en Inde, emploie environ 4000 personnes. Cependant, chaque année, nous connaissons un taux de rotation d'environ 15 % des employés. Ce taux de rotation est trop élevé et nous souhaitons le réduire afin d’améliorer notre réputation auprès des fournisseurs et des clients. De plus, chaque nouvel employé nécessite une période d’adaptation et de formation lors de son arrivée dans l’entreprise, et n’est donc pas directement productif à 100%.\n",
    "\n",
    "Dans le cadre de diminuer le taux de rotation, nous avons décidé de développer une IA pour identifier les facteurs qui ont le plus d’influence sur le taux de rotations et donc trouver des pistes de solutions à ces problématiques.\n",
    "\n",
    "Nous avons à notre disposition des données récoltées dans l’entreprise. Celles-ci proviennent des Ressources Humaines, d’une enquête de satisfaction des employés, d’une évaluation des managers sur chaque employé et des horaires de travail des employés. \n",
    "\n",
    "Nous avons donc travaillé avec des données sensibles et personnelles. Nous avons donc adopter une réflexion éthique sur notre travail afin de s’assurer que notre travail a été effectué avec bienveillance et sans porter préjudice aux employés.\n",
    "\n",
    "Dans cette optique, notre projet d'IA a été conçu en tenant compte des préoccupations éthiques, et nous avons activement cherché à nous conformer aux recommandations établies par la Commission Européenne pour l'élaboration et l'utilisation responsables de l'intelligence artificielle. Dans le cadre de cet effort, nous avons particulièrement focalisé notre attention sur les sept exigences recommandées par la Commission Européenne, reconnaissant ainsi l'importance cruciale de l'éthique dans le développement et le déploiement de l'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Autonomie et capacité d’action de l’humain\n",
    "\n",
    "Le système d'intelligence artificielle pourrait engendrer de la confusion si les utilisateurs ne vérifient pas la validité des résultats obtenus, notamment en matière de prises de décision. Par exemple, il est impossible d'assurer qu'un employé décidera de quitter l'entreprise, même si les indicateurs de qualité du modèle Random Forest sont excellents.\n",
    "\n",
    "C’est pour cela qu’il convient d'examiner de manière critique les suggestions du système et de s'assurer de leur exactitude, afin d'éviter des décisions inutiles ou préjudiciables. Si cette vérification n'est pas effectuée, des décisions erronées pourraient être prises, pouvant nuire à la carrière des employés ou entraîner des investissements inefficaces de la part de l'entreprise.\n",
    "\n",
    "Il est également essentiel de mettre en place des mécanismes pour éviter une sur-reliance des utilisateurs sur le système d'IA. Par exemple, des enquêtes auprès des employés peuvent fournir des informations complémentaires pour valider les résultats du système et prendre des décisions éclairées.\n",
    "\n",
    "Enfin, il est nécessaire que le système protège les données personnelles conformément au RGPD. Cela a été inclue par l'anonymisation des données (utilisation d’un ID au lieu des noms et prénoms des employés) et la suppression des informations sensibles qui ne devraient pas être prises en compte pour évaluer si un employé envisage de quitter l'entreprise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Robustesse technique et sécurité\n",
    "\n",
    "Le système d'IA est protégé contre les cyber-attaques grâce à sa non-exposition publique, soulignant l'importance de la confidentialité et de la sécurité des données. Toutefois, des défis subsistent quant à la précision du modèle, la qualité et l'actualisation des données. Des limites éthiques et la complexité du comportement humain rendent difficile la garantie d'une précision absolue, malgré certains modèles intégrant des bons indicateurs de qualité. La communication sur le niveau de précision attendue reste complexe, mettant en lumière la nécessité de transparence et de responsabilité dans l'usage des systèmes d'IA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vie privée et gouvernance des données\n",
    "\n",
    "L'impact du système d'IA sur le droit à la vie privée, à l'intégrité physique, mentale et/ou morale, ainsi que sur le droit à la protection des données a été pris en considération. Les données sont anonymisées, avec les noms et prénoms remplacés par des identifiants. Cependant, en cas d'accès non autorisé, il est possible de remonter jusqu'à l'employé en utilisant des informations telles que l'âge, l'ancienneté, le niveau hiérarchique, etc.\n",
    "\n",
    "Plusieurs mesures ont été prises pour se conformer au Règlement général sur la protection des données (RGPD). Il n'y a pas de transmission des données à des tiers en dehors de l’entreprise. L'accès à l'IA est limité au personnel qualifié afin d’assurer une diffusion restreinte des résultats et donc indirectement des données. Des données personnelles telles que la distance entre le domicile et le lieu de travail, l'âge, le niveau d'éducation, le salaire brut, le pourcentage d'augmentation, etc., sont disponibles, ce qui peut permettre d'identifier les individus. Cependant, les décideurs n’auront accès uniquement aux résultats et non pas aux données initiales, ce qui limite la possibilité de nuire à la carrière d’employés. Les données potentiellement inutiles ont été éliminées du jeu de données pour limiter l'utilisation de données personnelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transparence\n",
    "\n",
    "Nous avons adopté des mesures pour assurer la traçabilité et l'évaluation continue de la qualité des données dans le système d'IA. Les données des Ressources Humaines sont fiables, tandis que celles des questionnaires aux employés sont plus subjectives mais jugées importantes. Le modèle Random Forest permet de retracer les données et les décisions prises, contrairement au Perceptron et au classificateur binaire. Les limitations techniques et les risques des systèmes d'IA, tels que la précision du modèle, le recall et le f1 score, ont été communiqués, soulignant le fait que les modèles ne garantissent pas une précision de 100%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Diversité, non-discrimination et équité\n",
    "\n",
    "Dans notre projet, nous avons pris des mesures pour éviter la création ou le renforcement de biais injustes dans le système d'IA, tant en ce qui concerne l'utilisation des données d'entrée que la conception de l'algorithme. Nous avons limité l'utilisation de données personnelles autant que possible, en ne conservant que celles que nous jugeons essentielles, telles que l'âge et le salaire des employés. De plus, nous avons inclus tous les employés de l'entreprise dans notre ensemble de données pour garantir une représentation diversifiée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bien-être de la société et de l’environnement\n",
    "\n",
    "L'intelligence artificielle mise en place n'affecte pas directement le travail des employés, mais vise plutôt à identifier les liens entre les départs d'employés et à prédire les risques de démissions futures. Pour ce qui est de l’environnement, notre intelligence artificielle n’a pas d’impact à proprement parlé sur elle, nous ne pouvons donc pas beaucoup nous prononcer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Responsabilité\n",
    "\n",
    "Il faut garder en tête que notre intelligence artificielle reste un outil, c’est un support qui nous permet de trouver des liens entre les personnes ayant démissionné de l’entreprise HumanForYou et de prédire les prochaines démissions, mais notre modèle peut se tromper. C’est pourquoi il faut garder un certain recul sur les résultats. De plus, pour garder une approche éthique nous avons supprimer des données pour qu’on ne puisse pas retrouver un employé juste avec nos données. Ce qui rend donc notre modèle un peu moins précis. \n",
    "\n",
    "Il faut donc faire de la prévention auprès de l’entreprise HumanForYou afin qu’elle est bien conscience n’est qu’un soutien pour résoudre leur problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concernant notre projet\n",
    "\n",
    "À l'ère actuelle, où la sensibilisation et l'importance cruciale de l'éthique dans la gestion des données est au centre de nos préoccupations, les entreprises prennent des mesures proactives pour s'assurer de la sécurité et de la confidentialité des informations personnelles de leurs employés. Ce principe éthique a été un pilier central dans la conception et l'exécution de notre projet. Afin d'adhérer à ces valeurs éthiques, nous avons procédé à des ajustements significatifs dans notre traitement des données, notamment en éliminant certaines variables du jeu de données, pour des raisons morales impératives.\n",
    "\n",
    "Plus précisément, nous avons identifié que les variables telles que l'identifiant de l’employé (EmployeeID), la distance entre le domicile et le lieu de travail (DistanceFromHome) et le domaine d'éducation (EducationField) étaient des vecteurs potentiels d'identification personnelle, présentant ainsi un risque pour la confidentialité des employés. En outre, les informations concernant le Genre (Gender) et l'État Civil (MaritalStatus) des employés étaient susceptibles de servir de fondement à des pratiques discriminatoires, basées sur le sexe ou le statut familial des individus. En retirant ces variables spécifiques de notre analyse, notre objectif a été de garantir la protection de la vie privée des employés tout en éliminant toute possibilité de discrimination.\n",
    "\n",
    "Par ailleurs, nous avons également décidé de ne pas inclure les évaluations fournies par les managers concernant leurs subordonnés. Ces évaluations sont subjectives et pourraient non seulement introduire un biais dans notre analyse mais également contribuer à des pratiques discriminatoires. En outre, ces évaluations pourraient indirectement permettre l'identification des employés à travers des détails spécifiques relatifs à leur performance. Sur le plan technique, la subjectivité de ces évaluations pose également un défi, car elles peuvent varier considérablement d'un superviseur à l'autre, ne reflétant pas nécessairement la réalité de la performance ou des compétences de l'employé de manière objective.\n",
    "\n",
    "À travers ces mesures, notre démarche vise à promouvoir une gestion des données respectueuse de l'éthique, en assurant la protection de la vie privée des employés et en s'opposant à toute forme de discrimination. Cette approche reflète notre engagement envers une utilisation responsable et morale des données, en accord avec les valeurs éthiques contemporaines qui guident de plus en plus les pratiques dans le monde des affaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "En conclusion, le développement de notre projet d'intelligence artificielle au sein de l'entreprise HumanForYou repose sur des fondements éthiques solides et une réflexion profonde quant à l'impact potentiel sur les individus et la société dans son ensemble. Nous avons déployé des efforts considérables pour garantir la transparence, la sécurité des données, la protection de la vie privée, et la non-discrimination dans notre démarche.\n",
    "\n",
    "En fin de compte, notre objectif est de fournir à HumanForYou un outil puissant pour identifier les tendances et les risques de rotation du personnel, tout en veillant à ce que cet outil soit utilisé de manière éthique et responsable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_env",
   "language": "python",
   "name": "algo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
